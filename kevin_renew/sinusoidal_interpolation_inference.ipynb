{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cell-0",
   "metadata": {},
   "source": "# Sinusoidal Neural Field Interpolation Evaluation\n\nThis notebook evaluates PixNerd's neural field interpolation capabilities for super-resolution.\n\n## Benchmark Design\n\n- **Training**: Model sees regularly sampled pixels (simulating low-res input)\n- **Testing**: Model must predict ALL pixels (super-resolution)\n- **Ground Truth**: Known sinusoidal patterns (smooth, continuous)\n\n### Super-Resolution Simulation\nRegular grid sampling simulates a downsampled low-resolution input:\n- `downsample_factor=4`: Every 4th pixel visible = 4x super-res (6.25% visible in 2D)\n- `downsample_factor=2`: Every 2nd pixel visible = 2x super-res (25% visible in 2D)\n\n### Key Metrics\n1. **Visible MSE**: Error on sampled positions (training data)\n2. **Invisible MSE**: Error on unseen positions (interpolation quality)\n3. **Interpolation Ratio**: invisible_mse / visible_mse (lower = better)"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# Setup paths\n",
    "NOTEBOOK_DIR = Path.cwd()\n",
    "PIXNERD_DIR = NOTEBOOK_DIR / \"PixNerd\"\n",
    "\n",
    "if PIXNERD_DIR.exists():\n",
    "    os.chdir(PIXNERD_DIR)\n",
    "    sys.path.insert(0, str(PIXNERD_DIR))\n",
    "    print(f\"Working directory: {os.getcwd()}\")\n",
    "else:\n",
    "    print(f\"ERROR: PixNerd directory not found at {PIXNERD_DIR}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import LinearSegmentedColormap\n",
    "\n",
    "torch._dynamo.config.disable = True\n",
    "\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-3",
   "metadata": {},
   "source": [
    "## Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-4",
   "metadata": {},
   "outputs": [],
   "source": "# =============================================================================\n# CONFIGURATION - Must match training!\n# =============================================================================\n\nCHECKPOINT_PATH = str(NOTEBOOK_DIR / \"workdirs/exp_sinusoidal_nf_test/checkpoints/last.ckpt\")\n\n# Dataset config\nRESOLUTION = 64  # High-res target\nCHANNELS = 1\nNUM_COMPONENTS = 5\n\n# Super-resolution config (must match training)\nDOWNSAMPLE_FACTOR = 4  # 4x super-res: every 4th pixel visible\nMASK_MODE = \"grid\"  # 2D grid sampling\n\n# Model config\nPATCH_SIZE = 4\nHIDDEN_SIZE = 256\nDECODER_HIDDEN_SIZE = 64\nNUM_ENCODER_BLOCKS = 6\nNUM_DECODER_BLOCKS = 2\nNUM_GROUPS = 4\n\n# Sampling\nNUM_SAMPLE_STEPS = 50\n\nDEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n\n# Compute visible ratio\nLOW_RES = RESOLUTION // DOWNSAMPLE_FACTOR\nif MASK_MODE == \"grid\":\n    VISIBLE_RATIO = 1.0 / (DOWNSAMPLE_FACTOR ** 2)\nelse:\n    VISIBLE_RATIO = 1.0 / DOWNSAMPLE_FACTOR\n\nprint(f\"Checkpoint: {CHECKPOINT_PATH}\")\nprint(f\"High-res target: {RESOLUTION}x{RESOLUTION}\")\nprint(f\"Low-res input: {LOW_RES}x{LOW_RES}\")\nprint(f\"Super-resolution: {DOWNSAMPLE_FACTOR}x\")\nprint(f\"Visible ratio: {VISIBLE_RATIO:.1%}\")"
  },
  {
   "cell_type": "markdown",
   "id": "cell-5",
   "metadata": {},
   "source": [
    "## Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.models.autoencoder.pixel import PixelAE\n",
    "from src.models.transformer.pixnerd_c2i_heavydecoder import PixNerDiT\n",
    "from src.diffusion.flow_matching.scheduling import LinearScheduler\n",
    "from src.diffusion.flow_matching.sampling import EulerSampler, ode_step_fn\n",
    "from src.diffusion.base.guidance import simple_guidance_fn\n",
    "\n",
    "# Import dataset utilities\n",
    "sys.path.insert(0, str(NOTEBOOK_DIR))\n",
    "from train_sinusoidal import SinusoidalPLModule, SinusoidalLightningModel, SimpleEMA\n",
    "from train_sinusoidal import UnconditionalConditioner, MaskedFlowMatchingTrainer\n",
    "from PixNerd.src.data.dataset.sinusoidal import (\n",
    "    generate_sinusoidal_image,\n",
    "    create_visibility_mask,\n",
    "    compute_interpolation_metrics,\n",
    ")\n",
    "\n",
    "\n",
    "def build_model():\n",
    "    scheduler = LinearScheduler()\n",
    "    vae = PixelAE(scale=1.0)\n",
    "    conditioner = UnconditionalConditioner()\n",
    "    \n",
    "    denoiser = PixNerDiT(\n",
    "        in_channels=CHANNELS,\n",
    "        patch_size=PATCH_SIZE,\n",
    "        num_groups=NUM_GROUPS,\n",
    "        hidden_size=HIDDEN_SIZE,\n",
    "        decoder_hidden_size=DECODER_HIDDEN_SIZE,\n",
    "        num_encoder_blocks=NUM_ENCODER_BLOCKS,\n",
    "        num_decoder_blocks=NUM_DECODER_BLOCKS,\n",
    "        num_classes=1,\n",
    "    )\n",
    "    \n",
    "    trainer = MaskedFlowMatchingTrainer(\n",
    "        scheduler=scheduler,\n",
    "        lognorm_t=True,\n",
    "        timeshift=1.0,\n",
    "    )\n",
    "    \n",
    "    sampler = EulerSampler(\n",
    "        num_steps=NUM_SAMPLE_STEPS,\n",
    "        guidance=1.0,\n",
    "        guidance_interval_min=0.0,\n",
    "        guidance_interval_max=1.0,\n",
    "        scheduler=scheduler,\n",
    "        w_scheduler=LinearScheduler(),\n",
    "        guidance_fn=simple_guidance_fn,\n",
    "        step_fn=ode_step_fn,\n",
    "    )\n",
    "    \n",
    "    ema_tracker = SimpleEMA(decay=0.9999)\n",
    "    \n",
    "    model = SinusoidalLightningModel(\n",
    "        vae=vae,\n",
    "        conditioner=conditioner,\n",
    "        denoiser=denoiser,\n",
    "        diffusion_trainer=trainer,\n",
    "        diffusion_sampler=sampler,\n",
    "        ema_tracker=ema_tracker,\n",
    "        optimizer=None,\n",
    "    )\n",
    "    \n",
    "    return model\n",
    "\n",
    "\n",
    "print(\"Building model...\")\n",
    "model = build_model()\n",
    "model.setup_ema()\n",
    "\n",
    "print(f\"\\nLoading checkpoint: {CHECKPOINT_PATH}\")\n",
    "if os.path.exists(CHECKPOINT_PATH):\n",
    "    checkpoint = torch.load(CHECKPOINT_PATH, map_location=DEVICE)\n",
    "    # Extract model state from Lightning checkpoint\n",
    "    state_dict = checkpoint.get('state_dict', checkpoint)\n",
    "    # Remove 'model.' prefix if present\n",
    "    new_state_dict = {}\n",
    "    for k, v in state_dict.items():\n",
    "        if k.startswith('model.'):\n",
    "            new_state_dict[k[6:]] = v\n",
    "        else:\n",
    "            new_state_dict[k] = v\n",
    "    model.load_state_dict(new_state_dict, strict=False)\n",
    "    print(\"Checkpoint loaded!\")\n",
    "else:\n",
    "    print(f\"WARNING: Checkpoint not found!\")\n",
    "\n",
    "model = model.to(DEVICE)\n",
    "model.eval()\n",
    "\n",
    "print(f\"\\nTotal parameters: {sum(p.numel() for p in model.denoiser.parameters()):,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-7",
   "metadata": {},
   "source": [
    "## Create Visibility Mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-8",
   "metadata": {},
   "outputs": [],
   "source": "# Create visibility mask (regular grid sampling)\nvisibility_mask = create_visibility_mask(\n    RESOLUTION, DOWNSAMPLE_FACTOR, MASK_MODE\n)\n\nvisible_ratio = visibility_mask.sum() / visibility_mask.size\n\nprint(f\"Visibility mask shape: {visibility_mask.shape}\")\nprint(f\"Visible pixels: {visibility_mask.sum()} / {visibility_mask.size} ({visible_ratio:.1%})\")\nprint(f\"This simulates {LOW_RES}x{LOW_RES} → {RESOLUTION}x{RESOLUTION} super-resolution\")\n\n# Visualize mask\nfig, axes = plt.subplots(1, 2, figsize=(12, 5))\n\n# Full mask\naxes[0].imshow(visibility_mask, cmap='RdYlGn', interpolation='nearest')\naxes[0].set_title(f\"Visibility Mask ({visible_ratio:.1%} visible = green)\")\n\n# Zoomed view to show grid pattern\nzoom_size = 16\naxes[1].imshow(visibility_mask[:zoom_size, :zoom_size], cmap='RdYlGn', interpolation='nearest')\naxes[1].set_title(f\"Zoomed View (top-left {zoom_size}x{zoom_size})\")\nfor ax in axes:\n    ax.set_xlabel(\"x\")\n    ax.set_ylabel(\"y\")\n\nplt.tight_layout()\nplt.show()\n\nprint(f\"\\nGrid pattern: Every {DOWNSAMPLE_FACTOR}th pixel in both x and y directions\")"
  },
  {
   "cell_type": "markdown",
   "id": "cell-9",
   "metadata": {},
   "source": [
    "## Generate Ground Truth Samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-10",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_test_samples(num_samples=10, seed_start=1000):\n",
    "    \"\"\"Generate ground truth sinusoidal images for testing.\"\"\"\n",
    "    samples = []\n",
    "    for i in range(num_samples):\n",
    "        img = generate_sinusoidal_image(\n",
    "            RESOLUTION, NUM_COMPONENTS,\n",
    "            freq_range=(1.0, 8.0),\n",
    "            seed=seed_start + i\n",
    "        )\n",
    "        samples.append(img)\n",
    "    return np.stack(samples)\n",
    "\n",
    "\n",
    "# Generate test samples\n",
    "test_samples = generate_test_samples(10)\n",
    "print(f\"Generated {len(test_samples)} test samples\")\n",
    "\n",
    "# Display a few\n",
    "fig, axes = plt.subplots(2, 5, figsize=(15, 6))\n",
    "for i, (ax, img) in enumerate(zip(axes.flat, test_samples)):\n",
    "    ax.imshow(img, cmap='viridis')\n",
    "    ax.set_title(f\"Sample {i}\")\n",
    "    ax.axis('off')\n",
    "plt.suptitle(\"Ground Truth Sinusoidal Patterns\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-11",
   "metadata": {},
   "source": [
    "## Reconstruction Test\n",
    "\n",
    "Test 1: Given a noisy version of a sinusoidal image, can the model reconstruct it?\n",
    "\n",
    "The model was trained only on visible regions, but must predict ALL pixels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-12",
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def reconstruct_from_noise(model, num_samples=4):\n",
    "    \"\"\"Generate samples from pure noise.\"\"\"\n",
    "    model.eval()\n",
    "    \n",
    "    # Random noise\n",
    "    noise = torch.randn(num_samples, CHANNELS, RESOLUTION, RESOLUTION, device=DEVICE)\n",
    "    \n",
    "    # Get condition (dummy)\n",
    "    condition, uncondition = model.conditioner(noise)\n",
    "    \n",
    "    # Sample using EMA model\n",
    "    denoiser = model.ema_denoiser if model.ema_denoiser is not None else model.denoiser\n",
    "    \n",
    "    samples = model.diffusion_sampler(\n",
    "        denoiser,\n",
    "        noise,\n",
    "        condition,\n",
    "        uncondition,\n",
    "    )\n",
    "    \n",
    "    # Decode\n",
    "    images = model.vae.decode(samples)\n",
    "    \n",
    "    return images.clamp(0, 1).cpu().numpy()\n",
    "\n",
    "\n",
    "# Generate samples\n",
    "print(\"Generating samples from noise...\")\n",
    "generated = reconstruct_from_noise(model, num_samples=8)\n",
    "\n",
    "# Display\n",
    "fig, axes = plt.subplots(2, 4, figsize=(12, 6))\n",
    "for i, (ax, img) in enumerate(zip(axes.flat, generated)):\n",
    "    ax.imshow(img[0], cmap='viridis')  # [C, H, W] -> [H, W]\n",
    "    ax.set_title(f\"Generated {i}\")\n",
    "    ax.axis('off')\n",
    "plt.suptitle(\"Generated Samples from Noise\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "lxs4ithmv1",
   "source": "## Core Evaluation: Reconstruction-Based Interpolation Test\n\nThe key test for neural field interpolation:\n1. Take ground truth sinusoidal image\n2. Add noise (simulate diffusion forward process)\n3. Denoise with the model\n4. Compare reconstruction quality on **visible** vs **invisible** positions\n\nIf the neural field interpolates well:\n- MSE on visible positions ≈ MSE on invisible positions\n- Interpolation ratio ≈ 1.0",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "id": "iz2jyb3usuj",
   "source": "@torch.no_grad()\ndef denoise_from_timestep(model, x0, t_start=0.8, num_steps=40):\n    \"\"\"\n    Denoise a clean image from a specific timestep.\n    \n    This simulates:\n    1. Adding noise to x0 up to timestep t_start\n    2. Denoising back to t=0\n    \n    Args:\n        model: The diffusion model\n        x0: Clean image [B, C, H, W]\n        t_start: Starting timestep (0=clean, 1=pure noise)\n        num_steps: Number of denoising steps\n    \n    Returns:\n        Denoised image [B, C, H, W]\n    \"\"\"\n    model.eval()\n    device = next(model.parameters()).device\n    \n    # Move to device\n    if not isinstance(x0, torch.Tensor):\n        x0 = torch.from_numpy(x0).float()\n    if x0.dim() == 3:\n        x0 = x0.unsqueeze(0)  # Add batch dim\n    if x0.dim() == 2:\n        x0 = x0.unsqueeze(0).unsqueeze(0)  # Add batch and channel dims\n    x0 = x0.to(device)\n    \n    batch_size = x0.shape[0]\n    \n    # Add noise: x_t = (1-t)*x0 + t*noise\n    noise = torch.randn_like(x0)\n    x_t = (1 - t_start) * x0 + t_start * noise\n    \n    # Get condition\n    condition, uncondition = model.conditioner(x_t)\n    \n    # Use EMA model\n    denoiser = model.ema_denoiser if model.ema_denoiser is not None else model.denoiser\n    \n    # Create timesteps from t_start to 0\n    timesteps = torch.linspace(t_start, 0, num_steps + 1, device=device)\n    \n    # Denoise step by step (Euler method)\n    x = x_t\n    for i in range(num_steps):\n        t_cur = timesteps[i]\n        t_next = timesteps[i + 1]\n        dt = t_next - t_cur  # negative\n        \n        # Predict velocity\n        t_batch = t_cur.repeat(batch_size)\n        v_pred = denoiser(x, t_batch, condition)\n        \n        # Euler step: x_next = x + v * dt\n        x = x + v_pred * dt\n    \n    return x.clamp(0, 1)\n\n\ndef evaluate_interpolation(model, ground_truth_images, mask, t_start=0.7, num_steps=40):\n    \"\"\"\n    Evaluate interpolation quality by reconstruction.\n    \n    Args:\n        model: Diffusion model\n        ground_truth_images: numpy array [N, H, W] or [N, C, H, W]\n        mask: Visibility mask [H, W]\n        t_start: Noise level for reconstruction test\n        num_steps: Denoising steps\n    \n    Returns:\n        Dict with metrics for each sample\n    \"\"\"\n    results = []\n    \n    for i, gt in enumerate(ground_truth_images):\n        # Ensure correct shape [1, C, H, W]\n        if gt.ndim == 2:\n            gt = gt[np.newaxis, np.newaxis, ...]  # [1, 1, H, W]\n        elif gt.ndim == 3:\n            gt = gt[np.newaxis, ...]  # [1, C, H, W]\n        \n        gt_tensor = torch.from_numpy(gt).float()\n        \n        # Denoise\n        reconstructed = denoise_from_timestep(model, gt_tensor, t_start, num_steps)\n        reconstructed = reconstructed.cpu().numpy()\n        \n        # Compute metrics\n        gt_np = gt.squeeze()  # [H, W]\n        recon_np = reconstructed.squeeze()  # [H, W]\n        \n        error = (gt_np - recon_np) ** 2\n        \n        visible_mse = error[mask].mean()\n        invisible_mse = error[~mask].mean()\n        full_mse = error.mean()\n        ratio = invisible_mse / (visible_mse + 1e-8)\n        \n        results.append({\n            'sample_idx': i,\n            'visible_mse': visible_mse,\n            'invisible_mse': invisible_mse,\n            'full_mse': full_mse,\n            'interpolation_ratio': ratio,\n            'ground_truth': gt_np,\n            'reconstructed': recon_np,\n        })\n        \n        print(f\"Sample {i}: visible_mse={visible_mse:.6f}, invisible_mse={invisible_mse:.6f}, ratio={ratio:.2f}\")\n    \n    return results\n\n\nprint(\"Evaluation functions defined.\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "5h98fcnciy8",
   "source": "# Run the interpolation evaluation\nprint(\"=\" * 60)\nprint(\"NEURAL FIELD INTERPOLATION EVALUATION\")\nprint(\"=\" * 60)\nprint(f\"\\nTest setup:\")\nprint(f\"  - Ground truth: {len(test_samples)} sinusoidal patterns\")\nprint(f\"  - Visible positions: {VISIBLE_RATIO:.1%} (training data)\")\nprint(f\"  - Invisible positions: {1-VISIBLE_RATIO:.1%} (interpolation test)\")\nprint(f\"  - Noise level (t_start): 0.7\")\nprint()\n\n# Evaluate on test samples\neval_results = evaluate_interpolation(\n    model, \n    test_samples, \n    visibility_mask, \n    t_start=0.7,  # Add 70% noise, then denoise\n    num_steps=40\n)\n\n# Summary statistics\nprint(\"\\n\" + \"=\" * 60)\nprint(\"SUMMARY\")\nprint(\"=\" * 60)\navg_visible = np.mean([r['visible_mse'] for r in eval_results])\navg_invisible = np.mean([r['invisible_mse'] for r in eval_results])\navg_ratio = np.mean([r['interpolation_ratio'] for r in eval_results])\n\nprint(f\"\\nAverage MSE on VISIBLE positions:   {avg_visible:.6f}\")\nprint(f\"Average MSE on INVISIBLE positions: {avg_invisible:.6f}\")\nprint(f\"Average Interpolation Ratio:        {avg_ratio:.2f}\")\nprint()\nif avg_ratio < 1.5:\n    print(\"✓ GOOD: Interpolation ratio < 1.5 - Neural field generalizes well!\")\nelif avg_ratio < 2.0:\n    print(\"~ OK: Interpolation ratio 1.5-2.0 - Decent interpolation\")\nelse:\n    print(\"✗ POOR: Interpolation ratio > 2.0 - Model struggles with unseen positions\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "6hkjg69o1ge",
   "source": "# Visualize reconstruction results\ndef visualize_reconstruction(result, mask, sample_idx=0):\n    \"\"\"Visualize ground truth vs reconstruction with error analysis.\"\"\"\n    gt = result['ground_truth']\n    recon = result['reconstructed']\n    error = np.abs(gt - recon)\n    \n    fig, axes = plt.subplots(2, 4, figsize=(16, 8))\n    \n    # Row 1: Ground truth, Reconstruction, Absolute Error, Squared Error\n    axes[0, 0].imshow(gt, cmap='viridis')\n    axes[0, 0].set_title(\"Ground Truth\")\n    axes[0, 0].axis('off')\n    \n    axes[0, 1].imshow(recon, cmap='viridis')\n    axes[0, 1].set_title(\"Reconstructed\")\n    axes[0, 1].axis('off')\n    \n    im = axes[0, 2].imshow(error, cmap='hot', vmin=0, vmax=0.3)\n    axes[0, 2].set_title(f\"Absolute Error (MSE={result['full_mse']:.4f})\")\n    axes[0, 2].axis('off')\n    plt.colorbar(im, ax=axes[0, 2])\n    \n    # Error histogram\n    axes[0, 3].hist(error[mask].flatten(), bins=50, alpha=0.7, label=f\"Visible ({result['visible_mse']:.4f})\", color='green')\n    axes[0, 3].hist(error[~mask].flatten(), bins=50, alpha=0.7, label=f\"Invisible ({result['invisible_mse']:.4f})\", color='red')\n    axes[0, 3].set_xlabel(\"Absolute Error\")\n    axes[0, 3].set_ylabel(\"Count\")\n    axes[0, 3].legend()\n    axes[0, 3].set_title(\"Error Distribution\")\n    \n    # Row 2: Error on visible, Error on invisible, Mask overlay, Difference map\n    visible_error = error.copy()\n    visible_error[~mask] = 0\n    im = axes[1, 0].imshow(visible_error, cmap='hot', vmin=0, vmax=0.3)\n    axes[1, 0].set_title(f\"Error on VISIBLE (MSE={result['visible_mse']:.4f})\")\n    axes[1, 0].axis('off')\n    \n    invisible_error = error.copy()\n    invisible_error[mask] = 0\n    im = axes[1, 1].imshow(invisible_error, cmap='hot', vmin=0, vmax=0.3)\n    axes[1, 1].set_title(f\"Error on INVISIBLE (MSE={result['invisible_mse']:.4f})\")\n    axes[1, 1].axis('off')\n    \n    # Show sampling grid overlay on ground truth\n    axes[1, 2].imshow(gt, cmap='viridis')\n    y_vis, x_vis = np.where(mask)\n    axes[1, 2].scatter(x_vis, y_vis, c='red', s=1, alpha=0.3)\n    axes[1, 2].set_title(f\"Sampling Grid ({VISIBLE_RATIO:.1%} visible)\")\n    axes[1, 2].axis('off')\n    \n    # Signed difference\n    diff = recon - gt\n    im = axes[1, 3].imshow(diff, cmap='RdBu', vmin=-0.3, vmax=0.3)\n    axes[1, 3].set_title(\"Signed Difference (blue=under, red=over)\")\n    axes[1, 3].axis('off')\n    plt.colorbar(im, ax=axes[1, 3])\n    \n    plt.suptitle(f\"Sample {sample_idx} - Interpolation Ratio: {result['interpolation_ratio']:.2f}x\", fontsize=14)\n    plt.tight_layout()\n    plt.show()\n\n\n# Visualize first few results\nfor i in range(min(4, len(eval_results))):\n    visualize_reconstruction(eval_results[i], visibility_mask, i)",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "w103gzapqgo",
   "source": "## Interpolation Quality vs Noise Level\n\nTest how interpolation quality varies with different starting noise levels.\nLower t_start = easier task (less noise to remove).",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "id": "lgg0mwpmv3n",
   "source": "# Test interpolation at different noise levels\nnoise_levels = [0.3, 0.5, 0.7, 0.9]\nnoise_level_results = {}\n\n# Use first 5 test samples for this analysis\ntest_subset = test_samples[:5]\n\nfor t_start in noise_levels:\n    print(f\"\\nTesting t_start = {t_start}...\")\n    results = evaluate_interpolation(model, test_subset, visibility_mask, t_start=t_start, num_steps=40)\n    \n    avg_visible = np.mean([r['visible_mse'] for r in results])\n    avg_invisible = np.mean([r['invisible_mse'] for r in results])\n    avg_ratio = np.mean([r['interpolation_ratio'] for r in results])\n    \n    noise_level_results[t_start] = {\n        'visible_mse': avg_visible,\n        'invisible_mse': avg_invisible,\n        'ratio': avg_ratio,\n    }\n\n# Plot results\nfig, axes = plt.subplots(1, 3, figsize=(15, 4))\n\nt_values = list(noise_level_results.keys())\nvisible_mses = [noise_level_results[t]['visible_mse'] for t in t_values]\ninvisible_mses = [noise_level_results[t]['invisible_mse'] for t in t_values]\nratios = [noise_level_results[t]['ratio'] for t in t_values]\n\naxes[0].plot(t_values, visible_mses, 'g-o', label='Visible (trained)')\naxes[0].plot(t_values, invisible_mses, 'r-o', label='Invisible (interpolated)')\naxes[0].set_xlabel('Noise Level (t_start)')\naxes[0].set_ylabel('MSE')\naxes[0].set_title('MSE vs Noise Level')\naxes[0].legend()\naxes[0].grid(True, alpha=0.3)\n\naxes[1].plot(t_values, ratios, 'b-o')\naxes[1].axhline(y=1.0, color='gray', linestyle='--', label='Ideal (ratio=1)')\naxes[1].set_xlabel('Noise Level (t_start)')\naxes[1].set_ylabel('Interpolation Ratio')\naxes[1].set_title('Interpolation Ratio vs Noise Level')\naxes[1].legend()\naxes[1].grid(True, alpha=0.3)\n\n# Bar chart comparison\nx = np.arange(len(t_values))\nwidth = 0.35\naxes[2].bar(x - width/2, visible_mses, width, label='Visible', color='green', alpha=0.7)\naxes[2].bar(x + width/2, invisible_mses, width, label='Invisible', color='red', alpha=0.7)\naxes[2].set_xlabel('Noise Level')\naxes[2].set_ylabel('MSE')\naxes[2].set_title('Visible vs Invisible MSE')\naxes[2].set_xticks(x)\naxes[2].set_xticklabels([f't={t}' for t in t_values])\naxes[2].legend()\n\nplt.tight_layout()\nplt.show()\n\n# Summary table\nprint(\"\\n\" + \"=\" * 60)\nprint(\"NOISE LEVEL ANALYSIS SUMMARY\")\nprint(\"=\" * 60)\nprint(f\"{'Noise Level':<15} {'Visible MSE':<15} {'Invisible MSE':<15} {'Ratio':<10}\")\nprint(\"-\" * 55)\nfor t in t_values:\n    r = noise_level_results[t]\n    print(f\"{t:<15.1f} {r['visible_mse']:<15.6f} {r['invisible_mse']:<15.6f} {r['ratio']:<10.2f}\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "cell-13",
   "metadata": {},
   "source": [
    "## Interpolation Quality Analysis\n",
    "\n",
    "Key question: How well does the model predict UNSEEN regions?\n",
    "\n",
    "We compare:\n",
    "1. MSE on visible regions (training data)\n",
    "2. MSE on invisible regions (interpolation quality)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-14",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_interpolation(ground_truth, generated, mask):\n",
    "    \"\"\"\n",
    "    Visualize interpolation quality.\n",
    "    \n",
    "    Shows:\n",
    "    - Ground truth\n",
    "    - Generated image\n",
    "    - Error map\n",
    "    - Visible/invisible region errors\n",
    "    \"\"\"\n",
    "    fig, axes = plt.subplots(2, 3, figsize=(15, 10))\n",
    "    \n",
    "    # Ground truth\n",
    "    axes[0, 0].imshow(ground_truth, cmap='viridis')\n",
    "    axes[0, 0].set_title(\"Ground Truth\")\n",
    "    axes[0, 0].axis('off')\n",
    "    \n",
    "    # Generated\n",
    "    axes[0, 1].imshow(generated, cmap='viridis')\n",
    "    axes[0, 1].set_title(\"Generated\")\n",
    "    axes[0, 1].axis('off')\n",
    "    \n",
    "    # Error map\n",
    "    error = np.abs(ground_truth - generated)\n",
    "    im = axes[0, 2].imshow(error, cmap='hot', vmin=0, vmax=0.5)\n",
    "    axes[0, 2].set_title(\"Absolute Error\")\n",
    "    axes[0, 2].axis('off')\n",
    "    plt.colorbar(im, ax=axes[0, 2])\n",
    "    \n",
    "    # Visibility mask overlay\n",
    "    overlay = np.stack([ground_truth, ground_truth, ground_truth], axis=-1)\n",
    "    overlay[~mask] = [1, 0, 0]  # Red for invisible regions\n",
    "    axes[1, 0].imshow(overlay * 0.5 + 0.5 * ground_truth[..., np.newaxis])\n",
    "    axes[1, 0].set_title(\"Visibility Mask (red = unseen)\")\n",
    "    axes[1, 0].axis('off')\n",
    "    \n",
    "    # Error on visible regions only\n",
    "    visible_error = error.copy()\n",
    "    visible_error[~mask] = 0\n",
    "    im = axes[1, 1].imshow(visible_error, cmap='hot', vmin=0, vmax=0.5)\n",
    "    visible_mse = (error[mask] ** 2).mean()\n",
    "    axes[1, 1].set_title(f\"Error on VISIBLE ({visible_mse:.4f} MSE)\")\n",
    "    axes[1, 1].axis('off')\n",
    "    \n",
    "    # Error on invisible regions only\n",
    "    invisible_error = error.copy()\n",
    "    invisible_error[mask] = 0\n",
    "    im = axes[1, 2].imshow(invisible_error, cmap='hot', vmin=0, vmax=0.5)\n",
    "    invisible_mse = (error[~mask] ** 2).mean()\n",
    "    axes[1, 2].set_title(f\"Error on INVISIBLE ({invisible_mse:.4f} MSE)\")\n",
    "    axes[1, 2].axis('off')\n",
    "    \n",
    "    ratio = invisible_mse / (visible_mse + 1e-8)\n",
    "    plt.suptitle(f\"Interpolation Quality - Ratio: {ratio:.2f}x (lower = better)\", fontsize=14)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    return visible_mse, invisible_mse, ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-15",
   "metadata": {},
   "outputs": [],
   "source": "# Analyze interpolation quality on generated samples\n# Visualize the generated samples with the grid mask overlay\n\nfor i in range(min(4, len(generated))):\n    gen_img = generated[i, 0]  # [H, W]\n    \n    fig, axes = plt.subplots(1, 3, figsize=(12, 4))\n    \n    # Generated image\n    axes[0].imshow(gen_img, cmap='viridis')\n    axes[0].set_title(\"Generated\")\n    axes[0].axis('off')\n    \n    # With mask overlay (show sampled grid points)\n    overlay = gen_img.copy()\n    axes[1].imshow(overlay, cmap='viridis')\n    # Mark visible (sampled) positions\n    y_vis, x_vis = np.where(visibility_mask)\n    axes[1].scatter(x_vis, y_vis, c='red', s=2, alpha=0.5)\n    axes[1].set_title(f\"Sampled positions (red dots, {DOWNSAMPLE_FACTOR}x grid)\")\n    axes[1].axis('off')\n    \n    # Gradient magnitude (smoothness check)\n    grad_x = np.abs(np.diff(gen_img, axis=1))\n    grad_y = np.abs(np.diff(gen_img, axis=0))\n    axes[2].imshow(grad_x[:-1, :], cmap='hot')\n    axes[2].set_title(\"Horizontal Gradient (edges)\")\n    axes[2].axis('off')\n    \n    plt.suptitle(f\"Sample {i} Analysis\")\n    plt.tight_layout()\n    plt.show()"
  },
  {
   "cell_type": "markdown",
   "id": "cell-16",
   "metadata": {},
   "source": [
    "## Boundary Analysis\n",
    "\n",
    "Check if there are visible artifacts at the boundaries between visible and invisible regions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-17",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_boundaries(generated, mask):\n",
    "    \"\"\"\n",
    "    Analyze gradient magnitude at visibility boundaries.\n",
    "    \n",
    "    If interpolation is poor, we expect high gradients at boundaries.\n",
    "    \"\"\"\n",
    "    results = []\n",
    "    \n",
    "    for img in generated:\n",
    "        img = img[0]  # [H, W]\n",
    "        \n",
    "        # Compute gradient\n",
    "        grad_x = np.abs(np.diff(img, axis=1))\n",
    "        grad_x = np.pad(grad_x, ((0, 0), (0, 1)), mode='edge')\n",
    "        \n",
    "        # Find boundary pixels (where mask changes)\n",
    "        mask_diff = np.abs(np.diff(mask.astype(float), axis=1))\n",
    "        mask_diff = np.pad(mask_diff, ((0, 0), (0, 1)), mode='constant')\n",
    "        boundary_mask = mask_diff > 0\n",
    "        \n",
    "        # Gradient at boundaries vs elsewhere\n",
    "        grad_at_boundary = grad_x[boundary_mask].mean() if boundary_mask.any() else 0\n",
    "        grad_elsewhere = grad_x[~boundary_mask].mean()\n",
    "        \n",
    "        results.append({\n",
    "            'grad_at_boundary': grad_at_boundary,\n",
    "            'grad_elsewhere': grad_elsewhere,\n",
    "            'ratio': grad_at_boundary / (grad_elsewhere + 1e-8)\n",
    "        })\n",
    "    \n",
    "    return results\n",
    "\n",
    "\n",
    "# Analyze boundaries\n",
    "boundary_results = analyze_boundaries(generated, visibility_mask)\n",
    "\n",
    "print(\"Boundary Analysis:\")\n",
    "print(\"(Ratio close to 1.0 = good interpolation, no boundary artifacts)\")\n",
    "print()\n",
    "for i, r in enumerate(boundary_results):\n",
    "    print(f\"Sample {i}: boundary_grad={r['grad_at_boundary']:.4f}, \"\n",
    "          f\"other_grad={r['grad_elsewhere']:.4f}, ratio={r['ratio']:.2f}\")\n",
    "\n",
    "avg_ratio = np.mean([r['ratio'] for r in boundary_results])\n",
    "print(f\"\\nAverage boundary ratio: {avg_ratio:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-18",
   "metadata": {},
   "source": "## Summary\n\nThis benchmark tests neural field interpolation for super-resolution:\n\n1. **Training** on regularly sampled grid (simulating low-res input)\n2. **Evaluating** reconstruction quality on unseen positions\n3. **Checking** for artifacts in interpolated regions\n\n### Super-Resolution Setup\n- `downsample_factor=4`: 4x super-res (16x16 → 64x64)\n- Regular grid sampling (every 4th pixel in x and y)\n- ~6.25% visible pixels (256/4096)\n\n### Key Metrics:\n- **Interpolation ratio** < 2.0: Good interpolation\n- **Boundary ratio** ≈ 1.0: No grid artifacts\n- **Visual smoothness**: Generated patterns should be smooth sinusoids\n\n### Next Steps:\n- Try different downsample factors (2, 4, 8)\n- Test column-only or row-only sampling\n- Compare different model architectures"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}