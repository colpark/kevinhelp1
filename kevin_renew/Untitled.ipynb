{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4c47c990-901d-4b54-84b2-0288b6917a0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/pscratch/sd/k/kevinval/envs/pixnerd/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os, sys\n",
    "from pathlib import Path\n",
    "\n",
    "# Adjust this to your PixNerd repo root\n",
    "ROOT = Path(\"/pscratch/sd/k/kevinval/PNBase/PixNerd\")\n",
    "os.chdir(ROOT)\n",
    "sys.path.insert(0, str(ROOT))\n",
    "\n",
    "import torch\n",
    "from functools import partial\n",
    "from lightning.pytorch import Trainer\n",
    "from lightning.pytorch.callbacks import ModelCheckpoint, LearningRateMonitor\n",
    "from lightning.pytorch.loggers import CSVLogger, WandbLogger, TensorBoardLogger\n",
    "\n",
    "from src.models.autoencoder.pixel import PixelAE\n",
    "from src.models.conditioner.class_label import LabelConditioner\n",
    "from src.models.transformer.pixnerd_c2i_heavydecoder import PixNerDiT\n",
    "\n",
    "from src.diffusion.flow_matching.scheduling import LinearScheduler\n",
    "from src.diffusion.flow_matching.sampling import EulerSampler, ode_step_fn\n",
    "from src.diffusion.base.guidance import simple_guidance_fn\n",
    "from src.diffusion.flow_matching.training import FlowMatchingTrainer\n",
    "\n",
    "from src.callbacks.simple_ema import SimpleEMA\n",
    "from src.callbacks.save_images import SaveImagesHook\n",
    "from src.lightning_model import LightningModel\n",
    "from src.lightning_data import DataModule\n",
    "from src.data.dataset.cifar10 import PixCIFAR10, CIFAR10RandomNDataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "35d727a4-f694-44c1-93a3-94ad448d8791",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "current sampler is ODE sampler, but w_scheduler is enabled\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total parameters: 126,977,158\n",
      "Files already downloaded and verified\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using bfloat16 Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "You are using a CUDA device ('NVIDIA A100-SXM4-80GB') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output dir: workdirs/exp_cifar10_c2i_sparse_flowmatch_test\n",
      "Using CSVLogger\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "\n",
      "  | Name              | Type                | Params | Mode \n",
      "------------------------------------------------------------------\n",
      "0 | vae               | PixelAE             | 0      | eval \n",
      "1 | conditioner       | LabelConditioner    | 0      | eval \n",
      "2 | denoiser          | PixNerDiT           | 63.5 M | train\n",
      "3 | ema_denoiser      | PixNerDiT           | 63.5 M | eval \n",
      "4 | diffusion_sampler | EulerSampler        | 0      | train\n",
      "5 | diffusion_trainer | FlowMatchingTrainer | 0      | train\n",
      "------------------------------------------------------------------\n",
      "63.5 M    Trainable params\n",
      "63.5 M    Non-trainable params\n",
      "126 M     Total params\n",
      "507.909   Total estimated model params size (MB)\n",
      "147       Modules in train mode\n",
      "147       Modules in eval mode\n",
      "SLURM auto-requeueing enabled. Setting signal handlers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0:   0%|          | 0/391 [00:00<?, ?it/s] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/pscratch/sd/k/kevinval/envs/pixnerd/lib/python3.10/site-packages/torch/_inductor/lowering.py:1713: UserWarning: Torchinductor does not support code generation for complex operators. Performance may be worse than eager.\n",
      "  warnings.warn(\n",
      "/tmp/torchinductor_kevinval/4x/c4xa5ruwoxqqm6zxnmojclqdjdt3irc5psg4kvmbeqmz7bbovxjg.py:195: UserWarning: Casting complex values to real discards the imaginary part (Triggered internally at ../aten/src/ATen/native/Copy.cpp:308.)\n",
      "  buf20.copy_(buf19)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: 100%|█████████▉| 390/391 [01:16<00:00,  5.09it/s, v_num=0, loss=0.0927]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/pscratch/sd/k/kevinval/envs/pixnerd/lib/python3.10/site-packages/torch/autograd/graph.py:825: UserWarning: Error detected in MmBackward0. Traceback of forward call that caused the error:\n",
      "  File \"/pscratch/sd/k/kevinval/PNBase/PixNerd/src/models/transformer/pixnerd_c2i_heavydecoder.py\", line 310, in forward\n",
      "    s = self.blocks[i](s, condition, xpos)\n",
      "  File \"/pscratch/sd/k/kevinval/PNBase/PixNerd/src/models/transformer/pixnerd_c2i_heavydecoder.py\", line 99, in forward\n",
      "    x = x + gate_mlp * self.mlp(modulate(self.norm2(x), shift_mlp, scale_mlp))\n",
      "  File \"/pscratch/sd/k/kevinval/PNBase/PixNerd/src/models/layers/swiglu.py\", line 15, in forward\n",
      "    return self.w3(torch.nn.functional.silu(x1)*x2)\n",
      " (Triggered internally at ../torch/csrc/autograd/python_anomaly_mode.cpp:110.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "\n",
      "Detected KeyboardInterrupt, attempting graceful shutdown ...\n",
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from types import SimpleNamespace\n",
    "\n",
    "# -------------------------\n",
    "# Config / hyperparameters\n",
    "# -------------------------\n",
    "cfg = SimpleNamespace(\n",
    "    # training\n",
    "    max_steps       = 300_000,\n",
    "    batch_size      = 128,\n",
    "    lr              = 1e-4,\n",
    "    num_workers     = 4,\n",
    "\n",
    "    # model (same as train_cifar10.py)\n",
    "    hidden_size         = 512,\n",
    "    decoder_hidden_size = 64,\n",
    "    num_encoder_blocks  = 8,\n",
    "    num_decoder_blocks  = 2,\n",
    "    patch_size          = 8,\n",
    "    num_groups          = 8,\n",
    "    num_classes         = 10,\n",
    "\n",
    "    # flow matching / sampling\n",
    "    guidance        = 2.0,\n",
    "    num_sample_steps= 50,\n",
    "\n",
    "    # sparsity-conditioning\n",
    "    sparsity        = 0.4,   # total observed (cond + target), e.g. 40%\n",
    "    cond_fraction   = 0.5,   # fraction of observed used as cond (so 20% cond, 20% target)\n",
    "\n",
    "    # logging / trainer\n",
    "    exp_name        = \"cifar10_c2i_sparse_flowmatch_test\",\n",
    "    output_dir      = \"./workdirs\",\n",
    "    use_wandb       = False,\n",
    "    wandb_project   = \"pixnerd_cifar10\",\n",
    "    save_every_n_steps = 5_000,\n",
    "    val_every_n_epochs = 10,\n",
    "    resume          = None,\n",
    "    precision       = \"bf16-mixed\",\n",
    "    devices         = 1,\n",
    ")\n",
    "\n",
    "# -------------------------\n",
    "# Build model (same as build_model, but inline)\n",
    "# -------------------------\n",
    "main_scheduler = LinearScheduler()\n",
    "\n",
    "vae = PixelAE(scale=1.0)\n",
    "conditioner = LabelConditioner(num_classes=cfg.num_classes)\n",
    "\n",
    "denoiser = PixNerDiT(\n",
    "    in_channels=3,\n",
    "    patch_size=cfg.patch_size,\n",
    "    num_groups=cfg.num_groups,\n",
    "    hidden_size=cfg.hidden_size,\n",
    "    decoder_hidden_size=cfg.decoder_hidden_size,\n",
    "    num_encoder_blocks=cfg.num_encoder_blocks,\n",
    "    num_decoder_blocks=cfg.num_decoder_blocks,\n",
    "    num_classes=cfg.num_classes,\n",
    ")\n",
    "\n",
    "sampler = EulerSampler(\n",
    "    num_steps=cfg.num_sample_steps,\n",
    "    guidance=cfg.guidance,\n",
    "    guidance_interval_min=0.0,\n",
    "    guidance_interval_max=1.0,\n",
    "    scheduler=main_scheduler,\n",
    "    w_scheduler=LinearScheduler(),\n",
    "    guidance_fn=simple_guidance_fn,\n",
    "    step_fn=ode_step_fn,\n",
    ")\n",
    "\n",
    "fm_trainer = FlowMatchingTrainer(\n",
    "    scheduler=main_scheduler,\n",
    "    lognorm_t=True,\n",
    "    timeshift=1.0,\n",
    ")\n",
    "\n",
    "ema_tracker = SimpleEMA(decay=0.9999)\n",
    "optimizer_ctor = partial(torch.optim.AdamW, lr=cfg.lr, weight_decay=0.0)\n",
    "\n",
    "model = LightningModel(\n",
    "    vae=vae,\n",
    "    conditioner=conditioner,\n",
    "    denoiser=denoiser,\n",
    "    diffusion_trainer=fm_trainer,\n",
    "    diffusion_sampler=sampler,\n",
    "    ema_tracker=ema_tracker,\n",
    "    optimizer=optimizer_ctor,\n",
    "    lr_scheduler=None,\n",
    "    eval_original_model=False,\n",
    "    sparsity=cfg.sparsity,          # <--- your sparse conditioning\n",
    "    cond_fraction=cfg.cond_fraction # <--- cond vs target split\n",
    ")\n",
    "\n",
    "print(f\"Total parameters: {sum(p.numel() for p in model.parameters()):,}\")\n",
    "\n",
    "# -------------------------\n",
    "# Build datamodule (same as build_datamodule)\n",
    "# -------------------------\n",
    "train_dataset = PixCIFAR10(\n",
    "    root=\"./data\",\n",
    "    train=True,\n",
    "    random_flip=True,\n",
    "    download=True,\n",
    ")\n",
    "\n",
    "eval_dataset = CIFAR10RandomNDataset(\n",
    "    num_classes=cfg.num_classes,\n",
    "    latent_shape=(3, 32, 32),\n",
    "    max_num_instances=1000,\n",
    ")\n",
    "\n",
    "pred_dataset = CIFAR10RandomNDataset(\n",
    "    num_classes=cfg.num_classes,\n",
    "    latent_shape=(3, 32, 32),\n",
    "    max_num_instances=1000,\n",
    ")\n",
    "\n",
    "datamodule = DataModule(\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=eval_dataset,\n",
    "    pred_dataset=pred_dataset,\n",
    "    train_batch_size=cfg.batch_size,\n",
    "    train_num_workers=cfg.num_workers,\n",
    "    pred_batch_size=64,\n",
    "    pred_num_workers=2,\n",
    ")\n",
    "\n",
    "# -------------------------\n",
    "# Logging, callbacks, Trainer (same as main())\n",
    "# -------------------------\n",
    "output_dir = Path(cfg.output_dir) / f\"exp_{cfg.exp_name}\"\n",
    "output_dir.mkdir(parents=True, exist_ok=True)\n",
    "print(\"Output dir:\", output_dir)\n",
    "\n",
    "# logger choice\n",
    "if cfg.use_wandb:\n",
    "    logger = WandbLogger(\n",
    "        project=cfg.wandb_project,\n",
    "        name=cfg.exp_name,\n",
    "        save_dir=str(output_dir),\n",
    "    )\n",
    "else:\n",
    "    # use TensorBoard if available, else CSV\n",
    "    try:\n",
    "        import tensorboard  # noqa\n",
    "        from lightning.pytorch.loggers import TensorBoardLogger\n",
    "        logger = TensorBoardLogger(\n",
    "            save_dir=str(output_dir),\n",
    "            name=\"logs\",\n",
    "        )\n",
    "    except Exception:\n",
    "        logger = CSVLogger(\n",
    "            save_dir=str(output_dir),\n",
    "            name=\"logs\",\n",
    "        )\n",
    "        print(\"Using CSVLogger\")\n",
    "\n",
    "callbacks = [\n",
    "    ModelCheckpoint(\n",
    "        dirpath=output_dir / \"checkpoints\",\n",
    "        every_n_train_steps=cfg.save_every_n_steps,\n",
    "        save_top_k=-1,\n",
    "        save_last=True,\n",
    "    ),\n",
    "    LearningRateMonitor(logging_interval=\"step\"),\n",
    "    SaveImagesHook(\n",
    "        save_dir=\"val\",\n",
    "        save_compressed=True,\n",
    "    ),\n",
    "]\n",
    "\n",
    "trainer = Trainer(\n",
    "    default_root_dir=str(output_dir),\n",
    "    accelerator=\"auto\",\n",
    "    devices=cfg.devices,\n",
    "    precision=cfg.precision,\n",
    "    max_steps=cfg.max_steps,\n",
    "    check_val_every_n_epoch=cfg.val_every_n_epochs,\n",
    "    num_sanity_val_steps=0,\n",
    "    log_every_n_steps=50,\n",
    "    logger=logger,\n",
    "    callbacks=callbacks,\n",
    ")\n",
    "\n",
    "# -------------------------\n",
    "# Start training from notebook\n",
    "# -------------------------\n",
    "trainer.fit(\n",
    "    model,\n",
    "    datamodule=datamodule,\n",
    "    ckpt_path=cfg.resume,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96ebcdb6-4980-48d0-9f0c-ddd118b18239",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pixnerd (/pscratch)",
   "language": "python",
   "name": "pixnerd"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
